{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Scale CNN Cascade Network\n",
    "\n",
    "This notebook implements the multi scale cnn cascasde network proposed in the paper WIDER FACES"
   ]
  },
  {
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import cv2 as cv\n",
    "from glob import iglob\n",
    "import numpy as np\n",
    "import numpy.random as np_rand\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers"
   ],
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "execution_count": 120,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_from_google_drive(id, destination):\n",
    "    \n",
    "    def get_confirm_token(response):\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                return value\n",
    "\n",
    "        return None\n",
    "\n",
    "    def save_response_content(response, destination):\n",
    "        CHUNK_SIZE = 32768\n",
    "\n",
    "        with open(destination, \"wb\") as f:\n",
    "            for chunk in response.iter_content(CHUNK_SIZE):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "current_path = os.getcwd()\n",
    "data_path = os.path.join(current_path, \"data\")\n",
    "\n",
    "# make data directory\n",
    "try:\n",
    "    os.makedirs(data_path)\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download wider face training data\n",
    "if not os.path.exists(os.path.join(data_path, \"train.zip\")) and \\\n",
    "    not os.path.exists(os.path.join(data_path, 'WIDER_train')):\n",
    "    \n",
    "    print(\"downloading ... train.zip -- 1.47 GB\")\n",
    "    download_file_from_google_drive(\n",
    "        \"0B6eKvaijfFUDQUUwd21EckhUbWs\", \n",
    "        os.path.join(data_path,\"train.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download wider face validation data\n",
    "if not os.path.exists(os.path.join(data_path,\"val.zip\")) and \\\n",
    "    not os.path.exists(os.path.join(data_path, 'WIDER_val')):\n",
    "    print(\"downloading ... val.zip -- 362.8 MB\")\n",
    "    download_file_from_google_drive(\n",
    "        \"0B6eKvaijfFUDd3dIRmpvSk8tLUk\", \n",
    "        os.path.join(data_path,\"val.zip\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download annotations\n",
    "url = 'http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/support/bbx_annotation/wider_face_split.zip'\n",
    "\n",
    "if not os.path.exists(os.path.join(data_path, 'wider_face_split.zip')) and \\\n",
    "    not os.path.exists(os.path.join(data_path, 'wider_face_split')):\n",
    "    print(\"downloading ... wider_face_split.zip -- 3.6 MB\")\n",
    "    r = requests.get(url, allow_redirects = True)\n",
    "    open(os.path.join(data_path, 'wider_face_split.zip'), 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip training data\n",
    "if not os.path.exists(os.path.join(data_path,\"WIDER_train\")):\n",
    "    with zipfile.ZipFile(os.path.join(data_path,\"train.zip\"),\"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip validation data\n",
    "if not os.path.exists(os.path.join(data_path,\"WIDER_val\")):\n",
    "    with zipfile.ZipFile(os.path.join(data_path,\"val.zip\"),\"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip annotations\n",
    "if not os.path.exists(os.path.join(data_path,\"wider_face_split\")):\n",
    "    with zipfile.ZipFile(os.path.join(data_path,\"wider_face_split.zip\"),\"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove zip files\n",
    "if os.path.exists(os.path.join(data_path, \"wider_face_split.zip\")):\n",
    "    os.remove(os.path.join(data_path, \"wider_face_split.zip\"))\n",
    "if os.path.exists(os.path.join(data_path, \"train.zip\")):\n",
    "    os.remove(os.path.join(data_path, \"train.zip\"))\n",
    "if os.path.exists(os.path.join(data_path, \"val.zip\")):\n",
    "    os.remove(os.path.join(data_path, \"val.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = os.path.join(data_path, \"wider_face_split/wider_face_train_bbx_gt.txt\")\n",
    "val_annotations = os.path.join(data_path, \"wider_face_split/wider_face_val_bbx_gt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations(path, size = -1):\n",
    "    # open file and read each line\n",
    "    f = open(path, 'r')\n",
    "    lines = f.readlines()\n",
    "    # create empty array for training data\n",
    "    training_data = []\n",
    "    # iterate over lines\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        # return if enough samples have been found\n",
    "        if size > 0 and len(training_data) >= size:\n",
    "            return training_data\n",
    "        # initialize new picture\n",
    "        picture = {}\n",
    "        # picture must start with file path\n",
    "        assert lines[i].endswith(\".jpg\\n\"), \"read fault \" + lines[i]\n",
    "        picture['path'] = lines[i][:-1] # remove \\n character\n",
    "        # next line contains number of faces\n",
    "        i += 1\n",
    "        number_of_faces = max(1, int(lines[i]))\n",
    "        i += 1\n",
    "        faces = []\n",
    "        for j in range(i, i + number_of_faces):\n",
    "            face = {}\n",
    "            features = lines[j]\n",
    "            features = features.split(' ')\n",
    "            x, y, w, h = features[:4]\n",
    "            face['bb'] = [int(x),int(y), int(x) + int(w), int(y) + int(h)]\n",
    "            face['blur'] = int(features[4])\n",
    "            face['expression'] = int(features[5])\n",
    "            face['illumination'] = int(features[6])\n",
    "            face['occlusion'] = int(features[7])\n",
    "            face['pose'] = int(features[8])\n",
    "            face['invalid'] = int(features[9])\n",
    "            faces.append(face)\n",
    "\n",
    "        # increase the counter\n",
    "        i += number_of_faces\n",
    "        # add picture to training set\n",
    "        picture['faces'] = faces\n",
    "        training_data.append(picture)\n",
    "\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_annotations(train_annotations)\n",
    "val_data = read_annotations(val_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Samples : 12880\nValidation Samples:  3226\n"
     ]
    }
   ],
   "source": [
    "print('Train Samples :', len(train_data))\n",
    "print('Validation Samples: ', len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(box, faces):\n",
    "    \n",
    "    bbs = np.array([face['bb'] for face in faces], dtype = np.float32)\n",
    "    box_area = (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\n",
    "    area = (bbs[:, 2] - bbs[:, 0] + 1) * (bbs[:, 3] - bbs[:, 1] + 1)\n",
    "    xx1 = np.maximum(box[0], bbs[:, 0])\n",
    "    yy1 = np.maximum(box[1], bbs[:, 1])\n",
    "    xx2 = np.minimum(box[2], bbs[:, 2])\n",
    "    yy2 = np.minimum(box[3], bbs[:, 3])\n",
    "\n",
    "    # compute the width and height of the bounding box\n",
    "    w = np.maximum(0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "    inter = w * h\n",
    "    ovr = inter / (box_area + area - inter)\n",
    "    return ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_training_data(pixels, annotations, data_path, im_dir):\n",
    "    '''\n",
    "    pixels = 12\n",
    "    annotations = train_data\n",
    "    im_dir = 'WIDER_train/images/'\n",
    "    '''\n",
    "\n",
    "    directory = os.path.join(data_path, 'raw_' + str(pixels))\n",
    "    positives = os.path.join(directory, 'pos')\n",
    "    negatives = os.path.join(directory, 'neg')\n",
    "    partials = os.path.join(directory, 'part')\n",
    "\n",
    "    files = []\n",
    "    # create directories and textfiles\n",
    "    for dir in [directory, positives, negatives, partials]:\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "        \n",
    "    for dir in [positives, negatives, partials]:\n",
    "        if not os.path.exists(os.path.join(dir, str(pixels) + '.txt')):\n",
    "            f = open(os.path.join(dir, str(pixels) + '.txt'), 'w')\n",
    "            files.append(f)\n",
    "\n",
    "    if len(files) == 3:\n",
    "        pos_file, neg_file, part_file = files\n",
    "\n",
    "    idx, p_idx, n_idx, d_idx, face_idx = [0]*5\n",
    "\n",
    "\n",
    "    for anno in annotations:\n",
    "\n",
    "        img_path = anno['path']\n",
    "        faces = anno['faces']\n",
    "        img = cv.imread(os.path.join(data_path, im_dir + img_path))\n",
    "\n",
    "        if idx % 1000 == 0:\n",
    "            print(idx, ' images done')\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        # generate negatives\n",
    "        num_negs = 0\n",
    "        while num_negs < 50:\n",
    "            size = np_rand.randint(40, min(width, height) / 2)\n",
    "            x = np_rand.randint(0, width - size)\n",
    "            y = np_rand.randint(0, height - size)\n",
    "            box = np.array([x, y, x + size, y + size])\n",
    "\n",
    "            cropped_im = img[y : y + size, x : x + size]\n",
    "            resized_im = cv.resize(cropped_im, (pixels, pixels), interpolation = cv.INTER_LINEAR)\n",
    "\n",
    "            if np.max(intersection_over_union(box, faces)) < 0.3:\n",
    "                save_path = os.path.join(negatives, '%s.jpg' % n_idx)\n",
    "                neg_file.write(save_path + ' 0\\n')\n",
    "                cv.imwrite(save_path, resized_im)\n",
    "                n_idx += 1\n",
    "                num_negs += 1\n",
    "            \n",
    "        # print('%s images done, pos: %s part: %s neg: %s' % (idx, p_idx, d_idx, n_idx))\n",
    "\n",
    "        # generate positives\n",
    "        for face in faces:\n",
    "            x1, y1, x2, y2 = face['bb']\n",
    "            w = x2 - x1 + 1\n",
    "            h = y2 - y1 + 1\n",
    "\n",
    "            if max(w,h) < 40 or x1 < 0 or y1 < 0:\n",
    "                continue\n",
    "\n",
    "            for i in range(20):\n",
    "                size = np_rand.randint(int(min(w,h) * 0.8), np.ceil(1.25 * max(w,h)))\n",
    "                delta_x = np_rand.randint(-w * 0.2, w * 0.2)\n",
    "                delta_y = np_rand.randint(-h * 0.2, h * 0.2)\n",
    "\n",
    "                nx1 = int(max(x1 + w / 2 + delta_x - size / 2, 0))\n",
    "                ny1 = int(max(y1 + h / 2 + delta_y - size / 2, 0))\n",
    "                nx2 = nx1 + size\n",
    "                ny2 = ny1 + size\n",
    "\n",
    "                if nx2 > width or ny2 > height:\n",
    "                    continue\n",
    "                box = np.array([nx1, ny1, nx2, ny2])\n",
    "\n",
    "                offset_x1 = (x1 - nx1) / float(size)\n",
    "                offset_y1 = (y1 - ny1) / float(size)\n",
    "                offset_x2 = (x2 - nx2) / float(size)\n",
    "                offset_y2 = (y2 - ny2) / float(size)\n",
    "\n",
    "                cropped_im = img[ny1: ny2, nx1: nx2, :]\n",
    "                resized_im = cv.resize(cropped_im, (pixels, pixels),interpolation=cv.INTER_LINEAR)\n",
    "                \n",
    "                i_o_u = intersection_over_union(box, [face])\n",
    "\n",
    "                if i_o_u >= 0.65:\n",
    "                    save_path = os.path.join(positives, '%s.jpg' % p_idx)\n",
    "                    pos_file.write(save_path + \n",
    "                        ' 1 %.2f %.2f %.2f %.2f\\n' % \\\n",
    "                        (offset_x1, offset_y1, offset_x2, offset_y2))\n",
    "                    cv.imwrite(save_path, resized_im)\n",
    "                    p_idx += 1\n",
    "                elif i_o_u >= 0.4:\n",
    "                    save_path = os.path.join(partials, '%s.jpg' % d_idx)\n",
    "                    part_file.write(save_path + \n",
    "                        ' -1 %.2f %.2f %.2f %.2f\\n' % \\\n",
    "                        (offset_x1, offset_y1, offset_x2, offset_y2))\n",
    "                    cv.imwrite(save_path, resized_im)\n",
    "                    d_idx += 1\n",
    "            face_idx += 1\n",
    "            # print('%s images done, pos: %s part: %s neg: %s' % (idx, p_idx, d_idx, n_idx))\n",
    "\n",
    "    for f in files:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_features(value):\n",
    "    return tf.train.Feature(byes_list = tf.train.BytesList(value=[value]))\n",
    "\n",
    "def view_bar(num, total):\n",
    "    rate = float(num) / total\n",
    "    rate_num = int(rate * 100) + 1\n",
    "    r = '\\r[%s%s]%d%%' % (\"#\" * rate_num, \" \" * (100 - rate_num), rate_num, )\n",
    "    sys.stdout.write(r)\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tf_records_pnet(data_path):\n",
    "    \n",
    "    pixels = 12\n",
    "    directory = os.path.join(data_path, 'raw_' + str(pixels))\n",
    "\n",
    "    # read files\n",
    "    files = []\n",
    "    for dir in ['pos_%s.txt' % pixels, 'neg_%s.txt' % pixels, 'part_%s' % pixels]:\n",
    "        with open(os.path.join(directory, dir), 'r') as f:\n",
    "            files.append(f.readlines())\n",
    "    pos, neg, part = files\n",
    "\n",
    "    print('positives \\n')\n",
    "\n",
    "    filename_cls = 'pnet_data_for_cls.tfrecords'\n",
    "    print('Writing')\n",
    "    examples = []\n",
    "\n",
    "    writer = tf.python_io.TFRecordWriter(filename_cls)\n",
    "    cur_ = 0\n",
    "    sum_ = len(pos)\n",
    "\n",
    "    for line in pos:\n",
    "        view_bar(cur_, sum_)\n",
    "        cur_ += 1\n",
    "        words = line.split()\n",
    "        image_file_name = words[0]\n",
    "        im = cv.imread(image_file_name)\n",
    "        h, w, ch = im.shape\n",
    "        if h is not pixels or w is not pixels:\n",
    "            im = cv.resize(im, (pixels, pixels))\n",
    "        im = im.astype('uint8')\n",
    "        label = np.array([0,1], dtype = 'float32')\n",
    "        label_raw = label.tostring()\n",
    "        image_raw = im.tostring()\n",
    "        example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "            'label_raw' : bytes_feature(label_raw),\n",
    "            'image_raw' : bytes_feature(image_raw)}))\n",
    "        examples.append(example)\n",
    "\n",
    "    print('negatives \\n')\n",
    "    cur_ = 0\n",
    "    neg_keep = np_rand.choice(len(neg), size = 1000000, replace = False)\n",
    "    sum_ = len(neg_keep)\n",
    "    for i in neg_keep:\n",
    "        line = neg[i]\n",
    "        view_bar(cur_, sum_)\n",
    "        cur_ += 1\n",
    "        words = line.split()\n",
    "        image_file_name = words[0]\n",
    "        im = cv.imread(image_file_name)\n",
    "        h, w, ch = im.shape\n",
    "\n",
    "        if h is not pixels or w is not pixels:\n",
    "            im = cv.resize(im, (pixels, pixels))\n",
    "\n",
    "        im = im.astype('uint8')\n",
    "                label = np.array([1, 0], dtype='float32')\n",
    "        label_raw = label.tostring()\n",
    "        image_raw = im.tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'label_raw': bytes_feature(label_raw),\n",
    "            'image_raw': bytes_feature(image_raw)}))\n",
    "        examples.append(example)\n",
    "    print(len(examples))\n",
    "    random.shuffle(examples)\n",
    "    for example in examples:\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "    print('\\n'+'pos')\n",
    "    cur_ = 0\n",
    "    filename_roi = 'pnet_data_for_bbx.tfrecords'\n",
    "    print('Writing')\n",
    "    sum_ = len(pos)\n",
    "    examples = []\n",
    "    writer = tf.python_io.TFRecordWriter(filename_roi)\n",
    "    for line in pos:\n",
    "        view_bar(cur_, sum_)\n",
    "        cur_ += 1\n",
    "        words = line.split()\n",
    "        image_file_name = words[0]\n",
    "        im = cv.imread(image_file_name)\n",
    "        h, w, ch = im.shape\n",
    "        if is not pixels or w is not pixels:\n",
    "            im = cv2.resize(im, (pixels, pixels))\n",
    "        im = im.astype('uint8')\n",
    "        label = np.array([float(words[2]), float(words[3]),\n",
    "                          float(words[4]), float(words[5])],\n",
    "                         dtype='float32')\n",
    "        label_raw = label.tostring()\n",
    "        image_raw = im.tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'label_raw': bytes_feature(label_raw),\n",
    "            'image_raw': bytes_feature(image_raw)}))\n",
    "        examples.append(example)\n",
    "\n",
    "    print('\\n'+'part')\n",
    "    cur_ = 0\n",
    "    part_keep = np_rand.choice(len(part), size=300000, replace=False)\n",
    "    sum_ = len(part_keep)\n",
    "    for i in part_keep:\n",
    "        view_bar(cur_, sum_)\n",
    "        line = part[i]\n",
    "        cur_ += 1\n",
    "        words = line.split()\n",
    "        image_file_name = words[0]\n",
    "        im = cv.imread(image_file_name)\n",
    "        h, w, ch = im.shape\n",
    "        if h is not pixels or is not pixels:\n",
    "            im = cv2.resize(im, (pixels, pixels))\n",
    "        im = im.astype('uint8')\n",
    "        label = np.array([float(words[2]), float(words[3]),\n",
    "                          float(words[4]), float(words[5])],\n",
    "                         dtype='float32')\n",
    "        label_raw = label.tostring()\n",
    "        image_raw = im.tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'label_raw': bytes_feature(label_raw),\n",
    "            'image_raw': bytes_feature(image_raw)}))\n",
    "        examples.append(example)\n",
    "    print(len(examples))\n",
    "    random.shuffle(examples)\n",
    "    for example in examples:\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}