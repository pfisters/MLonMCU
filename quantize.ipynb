{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, PReLU, Flatten, Softmax, ReLU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tools.data_handling import get_image_paths, sample_data, load_data\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PNet():\n",
    "        \n",
    "    X = Input(shape = (12, 12, 3), name='PNet_Input')\n",
    "    \n",
    "    L = Conv2D(10, kernel_size=(3, 3), strides=(1, 1), padding='valid', name='PNet_CONV1')(X)\n",
    "    L = ReLU(name='PNet_RELU1')(L)\n",
    "    L = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='PNet_MAXPOOL1')(L)\n",
    "\n",
    "    L = Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding='valid', name='PNet_CONV2')(L)\n",
    "    L = ReLU(name='PNet_RELU2')(L)\n",
    "\n",
    "    L = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='valid', name='PNet_CONV3')(L)\n",
    "    L = ReLU(name='PNet_RELU3')(L)\n",
    "\n",
    "    C = Conv2D(2, kernel_size=(1, 1), strides=(1, 1), name = 'PNet_CONV4')(L)\n",
    "    classifier = Softmax(name='FACE_CLASSIFIER')(C)\n",
    "    regressor = Conv2D(4, kernel_size=(1, 1), strides=(1, 1), name = 'BB_REGRESSION')(L)\n",
    "\n",
    "    return Model(X, [regressor, classifier], name = 'PNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNet():\n",
    "\n",
    "    X = Input(shape = (24,24,3), name='RNet_Input')\n",
    "\n",
    "    L = Conv2D(28, kernel_size=(3, 3), strides=(1, 1), padding='valid', name='RNet_CONV1')(X)\n",
    "    L = ReLU(name='RNet_RELU1')(L)\n",
    "    L = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='RNet_MAXPOOL1')(L)\n",
    "\n",
    "    L = Conv2D(48, kernel_size=(3, 3), strides=(1, 1), padding='valid', name='ENet_CONV2')(L)\n",
    "    L = ReLU(name='RNet_RELU2')(L)\n",
    "    L = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid', name='RNet_MAXPOOL2')(L)\n",
    "\n",
    "    L = Conv2D(64, kernel_size=(2, 2), strides=(1, 1), padding='valid', name='RNet_CONV3')(L)\n",
    "    L = ReLU(name='RNet_RELU3')(L)\n",
    "    L = Flatten(name = 'RNet_FLATTEN')(L)\n",
    "    L = Dense(128, name = 'RNet_DENSE1')(L)\n",
    "    L = ReLU(name = 'RNet_PRELU4')(L)\n",
    "\n",
    "    C = Dense(2, name = 'RNet_DENSE2')(L)\n",
    "    classifier = Softmax(axis=1, name = 'FACE_CLASSIFIER')(C)\n",
    "    regressor = Dense(4, name = 'BB_REGRESSION')(L)\n",
    "\n",
    "    return Model(X, [regressor, classifier], name = 'RNet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ONet():\n",
    "    \n",
    "    X = Input(shape = (48, 48, 3), name = 'ONet_input')\n",
    "\n",
    "    L = Conv2D(32, kernel_size= (3,3), strides = (1,1), padding = 'valid', name = 'ONet_CONV1')(X)\n",
    "    L = ReLU(name = 'ONet_RELU1')(L)\n",
    "    L = MaxPooling2D(pool_size = (3,3), strides = (2, 2), padding = 'same', name = 'RNet_MAXPOOL1')(L)\n",
    "        \n",
    "    L = Conv2D(64, kernel_size= (3,3), strides = (1,1), padding = 'valid', name = 'ONet_CONV2')(L)\n",
    "    L = ReLU(name = 'ONet_RELU2')(L)\n",
    "    L = MaxPooling2D(pool_size = (3,3), strides = (2, 2), padding = 'valid', name = 'RNet_MAXPOOL2')(L)\n",
    "        \n",
    "    L = Conv2D(64, kernel_size= (3,3), strides = (1,1), padding = 'valid', name = 'ONet_CONV3')(L)\n",
    "    L = ReLU(name = 'ONet_RELU3')(L)\n",
    "    L = MaxPooling2D(pool_size = (2, 2), strides=(2, 2), padding = 'same', name = 'RNet_MAXPOOL3')(L)\n",
    "    \n",
    "    L = Conv2D(128, kernel_size= (2,2), strides = (1, 1), padding = 'valid', name = 'ONet_CONV4')(L)\n",
    "    L = ReLU(name='ONet_RELU4')(L)\n",
    "    \n",
    "    L = Flatten(name = 'ONet_FLATTEN')(L)\n",
    "    L = Dense(256, name = 'ONet_DENSE1') (L)\n",
    "    L = ReLU(name = 'ONet_RELU5')(L)\n",
    "\n",
    "    C = Dense(2, name = 'ONet_DENSE2')(L)\n",
    "    classifier = Softmax(axis = 1, name = 'FACE_CLASSIFIER')(C)\n",
    "    regressor = Dense(4, name = 'BB_REGRESSION')(L)\n",
    "\n",
    "    return Model(X, [regressor, classifier], name = 'ONet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = 48\n",
    "model = ONet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'onet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ONet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ONet_input (InputLayer)         [(None, 48, 48, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ONet_CONV1 (Conv2D)             (None, 46, 46, 32)   896         ONet_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ONet_RELU1 (ReLU)               (None, 46, 46, 32)   0           ONet_CONV1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RNet_MAXPOOL1 (MaxPooling2D)    (None, 23, 23, 32)   0           ONet_RELU1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ONet_CONV2 (Conv2D)             (None, 21, 21, 64)   18496       RNet_MAXPOOL1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ONet_RELU2 (ReLU)               (None, 21, 21, 64)   0           ONet_CONV2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RNet_MAXPOOL2 (MaxPooling2D)    (None, 10, 10, 64)   0           ONet_RELU2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ONet_CONV3 (Conv2D)             (None, 8, 8, 64)     36928       RNet_MAXPOOL2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ONet_RELU3 (ReLU)               (None, 8, 8, 64)     0           ONet_CONV3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RNet_MAXPOOL3 (MaxPooling2D)    (None, 4, 4, 64)     0           ONet_RELU3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ONet_CONV4 (Conv2D)             (None, 3, 3, 128)    32896       RNet_MAXPOOL3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ONet_RELU4 (ReLU)               (None, 3, 3, 128)    0           ONet_CONV4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ONet_FLATTEN (Flatten)          (None, 1152)         0           ONet_RELU4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ONet_DENSE1 (Dense)             (None, 256)          295168      ONet_FLATTEN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ONet_RELU5 (ReLU)               (None, 256)          0           ONet_DENSE1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ONet_DENSE2 (Dense)             (None, 2)            514         ONet_RELU5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "BB_REGRESSION (Dense)           (None, 4)            1028        ONet_RELU5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "FACE_CLASSIFIER (Softmax)       (None, 2)            0           ONet_DENSE2[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 385,926\n",
      "Trainable params: 385,926\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training data\n",
    "training_image_paths = get_image_paths(pixels, 'raw')\n",
    "t_lengths = []\n",
    "for path in training_image_paths:\n",
    "    (_, anno_path) = path\n",
    "    anno = open(anno_path, 'r')\n",
    "    t_lengths.append(len(anno.readlines()))\n",
    "validation_image_paths = get_image_paths(pixels, 'val')\n",
    "v_lengths = []\n",
    "for path in validation_image_paths:\n",
    "    (_, anno_path) = path\n",
    "    anno = open(anno_path, 'r')\n",
    "    v_lengths.append(len(anno.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_split, v_split = [1, 0, 1], [1, 0, 1]\n",
    "training_size = 1000\n",
    "validation_size = 200\n",
    "t_numbers = [math.ceil(training_size / sum(t_split) * s) for s in t_split]\n",
    "v_numbers = [math.ceil(validation_size / sum(v_split) * s) for s in v_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, n in zip(t_lengths, t_numbers):\n",
    "    if l < n: logging.fatal('There are not enough samples')\n",
    "for l, n in zip(v_lengths, v_numbers):\n",
    "    if l < n: logging.fatal('There are not enough samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_samples = sample_data(t_numbers, training_image_paths)\n",
    "v_samples = sample_data(v_numbers, validation_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 672.46it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1575.77it/s]\n"
     ]
    }
   ],
   "source": [
    "t_data, t_cat, t_bbx = load_data(t_samples, pixels)\n",
    "v_data, v_cat, v_bbx = load_data(v_samples, pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 0.6246 - BB_REGRESSION_loss: 0.0085 - FACE_CLASSIFIER_loss: 0.6203 - BB_REGRESSION_accuracy: 0.4680 - BB_REGRESSION_mse: 0.0085 - FACE_CLASSIFIER_accuracy: 0.6390 - FACE_CLASSIFIER_mse: 0.2159\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.4946 - BB_REGRESSION_loss: 0.0074 - FACE_CLASSIFIER_loss: 0.4909 - BB_REGRESSION_accuracy: 0.2870 - BB_REGRESSION_mse: 0.0074 - FACE_CLASSIFIER_accuracy: 0.7780 - FACE_CLASSIFIER_mse: 0.1558\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.4436 - BB_REGRESSION_loss: 0.0065 - FACE_CLASSIFIER_loss: 0.4404 - BB_REGRESSION_accuracy: 0.4220 - BB_REGRESSION_mse: 0.0065 - FACE_CLASSIFIER_accuracy: 0.8110 - FACE_CLASSIFIER_mse: 0.1379\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 0.4407 - BB_REGRESSION_loss: 0.0069 - FACE_CLASSIFIER_loss: 0.4372 - BB_REGRESSION_accuracy: 0.4090 - BB_REGRESSION_mse: 0.0069 - FACE_CLASSIFIER_accuracy: 0.8200 - FACE_CLASSIFIER_mse: 0.1381\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 0.4300 - BB_REGRESSION_loss: 0.0064 - FACE_CLASSIFIER_loss: 0.4268 - BB_REGRESSION_accuracy: 0.4600 - BB_REGRESSION_mse: 0.0064 - FACE_CLASSIFIER_accuracy: 0.8280 - FACE_CLASSIFIER_mse: 0.1331\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 2s 106ms/step - loss: 0.4230 - BB_REGRESSION_loss: 0.0065 - FACE_CLASSIFIER_loss: 0.4197 - BB_REGRESSION_accuracy: 0.4420 - BB_REGRESSION_mse: 0.0065 - FACE_CLASSIFIER_accuracy: 0.8350 - FACE_CLASSIFIER_mse: 0.1289\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.3957 - BB_REGRESSION_loss: 0.0061 - FACE_CLASSIFIER_loss: 0.3927 - BB_REGRESSION_accuracy: 0.5450 - BB_REGRESSION_mse: 0.0061 - FACE_CLASSIFIER_accuracy: 0.8520 - FACE_CLASSIFIER_mse: 0.1208\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 0.3579 - BB_REGRESSION_loss: 0.0059 - FACE_CLASSIFIER_loss: 0.3549 - BB_REGRESSION_accuracy: 0.5100 - BB_REGRESSION_mse: 0.0059 - FACE_CLASSIFIER_accuracy: 0.8640 - FACE_CLASSIFIER_mse: 0.1067\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 0.3582 - BB_REGRESSION_loss: 0.0064 - FACE_CLASSIFIER_loss: 0.3550 - BB_REGRESSION_accuracy: 0.3840 - BB_REGRESSION_mse: 0.0064 - FACE_CLASSIFIER_accuracy: 0.8640 - FACE_CLASSIFIER_mse: 0.1044\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.3505 - BB_REGRESSION_loss: 0.0061 - FACE_CLASSIFIER_loss: 0.3475 - BB_REGRESSION_accuracy: 0.4040 - BB_REGRESSION_mse: 0.0061 - FACE_CLASSIFIER_accuracy: 0.8750 - FACE_CLASSIFIER_mse: 0.1035\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.3751 - BB_REGRESSION_loss: 0.0059 - FACE_CLASSIFIER_loss: 0.3722 - BB_REGRESSION_accuracy: 0.4790 - BB_REGRESSION_mse: 0.0059 - FACE_CLASSIFIER_accuracy: 0.8470 - FACE_CLASSIFIER_mse: 0.1148\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.3232 - BB_REGRESSION_loss: 0.0058 - FACE_CLASSIFIER_loss: 0.3203 - BB_REGRESSION_accuracy: 0.4220 - BB_REGRESSION_mse: 0.0058 - FACE_CLASSIFIER_accuracy: 0.8770 - FACE_CLASSIFIER_mse: 0.0952\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.2756 - BB_REGRESSION_loss: 0.0056 - FACE_CLASSIFIER_loss: 0.2728 - BB_REGRESSION_accuracy: 0.4220 - BB_REGRESSION_mse: 0.0056 - FACE_CLASSIFIER_accuracy: 0.8920 - FACE_CLASSIFIER_mse: 0.0810\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 0.2402 - BB_REGRESSION_loss: 0.0059 - FACE_CLASSIFIER_loss: 0.2373 - BB_REGRESSION_accuracy: 0.3990 - BB_REGRESSION_mse: 0.0059 - FACE_CLASSIFIER_accuracy: 0.9100 - FACE_CLASSIFIER_mse: 0.0701\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.2422 - BB_REGRESSION_loss: 0.0065 - FACE_CLASSIFIER_loss: 0.2390 - BB_REGRESSION_accuracy: 0.3780 - BB_REGRESSION_mse: 0.0065 - FACE_CLASSIFIER_accuracy: 0.8980 - FACE_CLASSIFIER_mse: 0.0731\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 0.2108 - BB_REGRESSION_loss: 0.0064 - FACE_CLASSIFIER_loss: 0.2076 - BB_REGRESSION_accuracy: 0.4480 - BB_REGRESSION_mse: 0.0064 - FACE_CLASSIFIER_accuracy: 0.9120 - FACE_CLASSIFIER_mse: 0.0615\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 0.1694 - BB_REGRESSION_loss: 0.0062 - FACE_CLASSIFIER_loss: 0.1662 - BB_REGRESSION_accuracy: 0.4370 - BB_REGRESSION_mse: 0.0062 - FACE_CLASSIFIER_accuracy: 0.9350 - FACE_CLASSIFIER_mse: 0.0478\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.1842 - BB_REGRESSION_loss: 0.0059 - FACE_CLASSIFIER_loss: 0.1812 - BB_REGRESSION_accuracy: 0.3720 - BB_REGRESSION_mse: 0.0059 - FACE_CLASSIFIER_accuracy: 0.9180 - FACE_CLASSIFIER_mse: 0.0545\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 0.1843 - BB_REGRESSION_loss: 0.0056 - FACE_CLASSIFIER_loss: 0.1815 - BB_REGRESSION_accuracy: 0.3610 - BB_REGRESSION_mse: 0.0056 - FACE_CLASSIFIER_accuracy: 0.9370 - FACE_CLASSIFIER_mse: 0.0531\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 0.1420 - BB_REGRESSION_loss: 0.0059 - FACE_CLASSIFIER_loss: 0.1391 - BB_REGRESSION_accuracy: 0.4140 - BB_REGRESSION_mse: 0.0059 - FACE_CLASSIFIER_accuracy: 0.9490 - FACE_CLASSIFIER_mse: 0.0398\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.1121 - BB_REGRESSION_loss: 0.0058 - FACE_CLASSIFIER_loss: 0.1092 - BB_REGRESSION_accuracy: 0.4300 - BB_REGRESSION_mse: 0.0058 - FACE_CLASSIFIER_accuracy: 0.9580 - FACE_CLASSIFIER_mse: 0.0296\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 0.1002 - BB_REGRESSION_loss: 0.0057 - FACE_CLASSIFIER_loss: 0.0973 - BB_REGRESSION_accuracy: 0.4280 - BB_REGRESSION_mse: 0.0057 - FACE_CLASSIFIER_accuracy: 0.9600 - FACE_CLASSIFIER_mse: 0.0278\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 2s 105ms/step - loss: 0.0827 - BB_REGRESSION_loss: 0.0057 - FACE_CLASSIFIER_loss: 0.0798 - BB_REGRESSION_accuracy: 0.3890 - BB_REGRESSION_mse: 0.0057 - FACE_CLASSIFIER_accuracy: 0.9660 - FACE_CLASSIFIER_mse: 0.0226\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 0.0877 - BB_REGRESSION_loss: 0.0056 - FACE_CLASSIFIER_loss: 0.0849 - BB_REGRESSION_accuracy: 0.4040 - BB_REGRESSION_mse: 0.0056 - FACE_CLASSIFIER_accuracy: 0.9690 - FACE_CLASSIFIER_mse: 0.0232\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 0.0721 - BB_REGRESSION_loss: 0.0053 - FACE_CLASSIFIER_loss: 0.0695 - BB_REGRESSION_accuracy: 0.4330 - BB_REGRESSION_mse: 0.0053 - FACE_CLASSIFIER_accuracy: 0.9770 - FACE_CLASSIFIER_mse: 0.0182\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 0.0744 - BB_REGRESSION_loss: 0.0055 - FACE_CLASSIFIER_loss: 0.0716 - BB_REGRESSION_accuracy: 0.4040 - BB_REGRESSION_mse: 0.0055 - FACE_CLASSIFIER_accuracy: 0.9740 - FACE_CLASSIFIER_mse: 0.0198\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 0.0603 - BB_REGRESSION_loss: 0.0053 - FACE_CLASSIFIER_loss: 0.0577 - BB_REGRESSION_accuracy: 0.4210 - BB_REGRESSION_mse: 0.0053 - FACE_CLASSIFIER_accuracy: 0.9790 - FACE_CLASSIFIER_mse: 0.0159\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.0835 - BB_REGRESSION_loss: 0.0058 - FACE_CLASSIFIER_loss: 0.0805 - BB_REGRESSION_accuracy: 0.3990 - BB_REGRESSION_mse: 0.0058 - FACE_CLASSIFIER_accuracy: 0.9730 - FACE_CLASSIFIER_mse: 0.0216\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0635 - BB_REGRESSION_loss: 0.0055 - FACE_CLASSIFIER_loss: 0.0607 - BB_REGRESSION_accuracy: 0.4140 - BB_REGRESSION_mse: 0.0055 - FACE_CLASSIFIER_accuracy: 0.9810 - FACE_CLASSIFIER_mse: 0.0165\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0664 - BB_REGRESSION_loss: 0.0059 - FACE_CLASSIFIER_loss: 0.0635 - BB_REGRESSION_accuracy: 0.4060 - BB_REGRESSION_mse: 0.0059 - FACE_CLASSIFIER_accuracy: 0.9770 - FACE_CLASSIFIER_mse: 0.0182\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 154ms/step - loss: 0.0420 - BB_REGRESSION_loss: 0.0055 - FACE_CLASSIFIER_loss: 0.0392 - BB_REGRESSION_accuracy: 0.4460 - BB_REGRESSION_mse: 0.0055 - FACE_CLASSIFIER_accuracy: 0.9860 - FACE_CLASSIFIER_mse: 0.0100\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0295 - BB_REGRESSION_loss: 0.0050 - FACE_CLASSIFIER_loss: 0.0270 - BB_REGRESSION_accuracy: 0.4080 - BB_REGRESSION_mse: 0.0050 - FACE_CLASSIFIER_accuracy: 0.9900 - FACE_CLASSIFIER_mse: 0.0072\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.0215 - BB_REGRESSION_loss: 0.0049 - FACE_CLASSIFIER_loss: 0.0191 - BB_REGRESSION_accuracy: 0.4290 - BB_REGRESSION_mse: 0.0049 - FACE_CLASSIFIER_accuracy: 0.9960 - FACE_CLASSIFIER_mse: 0.0042\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0145 - BB_REGRESSION_loss: 0.0047 - FACE_CLASSIFIER_loss: 0.0122 - BB_REGRESSION_accuracy: 0.4540 - BB_REGRESSION_mse: 0.0047 - FACE_CLASSIFIER_accuracy: 0.9970 - FACE_CLASSIFIER_mse: 0.0026\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0157 - BB_REGRESSION_loss: 0.0045 - FACE_CLASSIFIER_loss: 0.0134 - BB_REGRESSION_accuracy: 0.4220 - BB_REGRESSION_mse: 0.0045 - FACE_CLASSIFIER_accuracy: 0.9960 - FACE_CLASSIFIER_mse: 0.0031\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.0178 - BB_REGRESSION_loss: 0.0044 - FACE_CLASSIFIER_loss: 0.0156 - BB_REGRESSION_accuracy: 0.4560 - BB_REGRESSION_mse: 0.0044 - FACE_CLASSIFIER_accuracy: 0.9960 - FACE_CLASSIFIER_mse: 0.0041\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0109 - BB_REGRESSION_loss: 0.0046 - FACE_CLASSIFIER_loss: 0.0085 - BB_REGRESSION_accuracy: 0.4270 - BB_REGRESSION_mse: 0.0046 - FACE_CLASSIFIER_accuracy: 0.9980 - FACE_CLASSIFIER_mse: 0.0015\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.0133 - BB_REGRESSION_loss: 0.0044 - FACE_CLASSIFIER_loss: 0.0111 - BB_REGRESSION_accuracy: 0.4500 - BB_REGRESSION_mse: 0.0044 - FACE_CLASSIFIER_accuracy: 0.9950 - FACE_CLASSIFIER_mse: 0.0028\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0077 - BB_REGRESSION_loss: 0.0044 - FACE_CLASSIFIER_loss: 0.0055 - BB_REGRESSION_accuracy: 0.4560 - BB_REGRESSION_mse: 0.0044 - FACE_CLASSIFIER_accuracy: 0.9990 - FACE_CLASSIFIER_mse: 8.0272e-04\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.0069 - BB_REGRESSION_loss: 0.0044 - FACE_CLASSIFIER_loss: 0.0047 - BB_REGRESSION_accuracy: 0.4740 - BB_REGRESSION_mse: 0.0044 - FACE_CLASSIFIER_accuracy: 0.9990 - FACE_CLASSIFIER_mse: 9.7117e-04\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.0043 - BB_REGRESSION_loss: 0.0042 - FACE_CLASSIFIER_loss: 0.0022 - BB_REGRESSION_accuracy: 0.4570 - BB_REGRESSION_mse: 0.0042 - FACE_CLASSIFIER_accuracy: 1.0000 - FACE_CLASSIFIER_mse: 1.8620e-04\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.0035 - BB_REGRESSION_loss: 0.0039 - FACE_CLASSIFIER_loss: 0.0016 - BB_REGRESSION_accuracy: 0.4510 - BB_REGRESSION_mse: 0.0039 - FACE_CLASSIFIER_accuracy: 1.0000 - FACE_CLASSIFIER_mse: 6.6752e-05\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0032 - BB_REGRESSION_loss: 0.0037 - FACE_CLASSIFIER_loss: 0.0013 - BB_REGRESSION_accuracy: 0.4700 - BB_REGRESSION_mse: 0.0037 - FACE_CLASSIFIER_accuracy: 1.0000 - FACE_CLASSIFIER_mse: 5.7202e-05\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0032 - BB_REGRESSION_loss: 0.0039 - FACE_CLASSIFIER_loss: 0.0012 - BB_REGRESSION_accuracy: 0.4260 - BB_REGRESSION_mse: 0.0039 - FACE_CLASSIFIER_accuracy: 1.0000 - FACE_CLASSIFIER_mse: 5.6141e-05\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.0034 - BB_REGRESSION_loss: 0.0045 - FACE_CLASSIFIER_loss: 0.0011 - BB_REGRESSION_accuracy: 0.4660 - BB_REGRESSION_mse: 0.0045 - FACE_CLASSIFIER_accuracy: 1.0000 - FACE_CLASSIFIER_mse: 5.9041e-05\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.0034 - BB_REGRESSION_loss: 0.0046 - FACE_CLASSIFIER_loss: 0.0011 - BB_REGRESSION_accuracy: 0.4820 - BB_REGRESSION_mse: 0.0046 - FACE_CLASSIFIER_accuracy: 1.0000 - FACE_CLASSIFIER_mse: 3.9809e-05\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0029 - BB_REGRESSION_loss: 0.0038 - FACE_CLASSIFIER_loss: 0.0010 - BB_REGRESSION_accuracy: 0.4960 - BB_REGRESSION_mse: 0.0038 - FACE_CLASSIFIER_accuracy: 1.0000 - FACE_CLASSIFIER_mse: 4.9175e-05\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.0025 - BB_REGRESSION_loss: 0.0033 - FACE_CLASSIFIER_loss: 8.6304e-04 - BB_REGRESSION_accuracy: 0.4530 - BB_REGRESSION_mse: 0.0033 - FACE_CLASSIFIER_accuracy: 1.0000 - FACE_CLASSIFIER_mse: 2.7341e-05\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0025 - BB_REGRESSION_loss: 0.0035 - FACE_CLASSIFIER_loss: 7.3831e-04 - BB_REGRESSION_accuracy: 0.4990 - BB_REGRESSION_mse: 0.0035 - FACE_CLASSIFIER_accuracy: 1.0000 - FACE_CLASSIFIER_mse: 2.2825e-05\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0024 - BB_REGRESSION_loss: 0.0036 - FACE_CLASSIFIER_loss: 6.0843e-04 - BB_REGRESSION_accuracy: 0.4840 - BB_REGRESSION_mse: 0.0036 - FACE_CLASSIFIER_accuracy: 1.0000 - FACE_CLASSIFIER_mse: 1.0487e-05\n"
     ]
    }
   ],
   "source": [
    "losses = {\n",
    "    'FACE_CLASSIFIER' : tf.keras.losses.BinaryCrossentropy(),\n",
    "    'BB_REGRESSION' : tf.keras.losses.MeanSquaredError()\n",
    "}\n",
    "loss_weights = {\n",
    "    'FACE_CLASSIFIER' : 1.0,\n",
    "    'BB_REGRESSION' : 0.5\n",
    "}\n",
    "\n",
    "# compile model\n",
    "model.compile(\n",
    "    loss = losses,\n",
    "    loss_weights=loss_weights,\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy', 'mse']\n",
    ")\n",
    "\n",
    "# train\n",
    "H = model.fit(\n",
    "    x=t_data,\n",
    "    y={\n",
    "        'FACE_CLASSIFIER' : t_cat,\n",
    "        'BB_REGRESSION' : t_bbx\n",
    "        },\n",
    "    batch_size=64,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7603 - BB_REGRESSION_loss: 0.0059 - FACE_CLASSIFIER_loss: 0.7573 - BB_REGRESSION_accuracy: 0.5000 - BB_REGRESSION_mse: 0.0059 - FACE_CLASSIFIER_accuracy: 0.8800 - FACE_CLASSIFIER_mse: 0.1018\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(\n",
    "    x=v_data,\n",
    "    y={\n",
    "        'FACE_CLASSIFIER' : v_cat,\n",
    "        'BB_REGRESSION' : v_bbx\n",
    "        },\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7602623701095581,\n",
       " 0.005854387301951647,\n",
       " 0.7573351860046387,\n",
       " 0.5,\n",
       " 0.005854387301951647,\n",
       " 0.8799999952316284,\n",
       " 0.10176583379507065]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tf lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize = True\n",
    "if (quantize):\n",
    "    def representative_dataset():\n",
    "        for i in range(500):\n",
    "            yield([t_data[i].reshape(1,pixels,pixels,3)])\n",
    "    # Set the optimization flag.\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce full-int8 quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "    # Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/severinpfister/opt/anaconda3/envs/MLonMCU/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/severinpfister/opt/anaconda3/envs/MLonMCU/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/severinpfister/opt/anaconda3/envs/MLonMCU/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/severinpfister/opt/anaconda3/envs/MLonMCU/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/43/5blqqb3n63j88pcfn03dqgcm0000gn/T/tmp1v211t9j/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/43/5blqqb3n63j88pcfn03dqgcm0000gn/T/tmp1v211t9j/assets\n"
     ]
    }
   ],
   "source": [
    "tflitemodel = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402752"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(os.path.join(model_name + '.tflite'), 'wb').write(tflitemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_interpreter = tf.lite.Interpreter(model_path=model_name + '.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'ONet_input',\n",
       "  'index': 0,\n",
       "  'shape': array([ 1, 48, 48,  3], dtype=int32),\n",
       "  'shape_signature': array([-1, 48, 48,  3], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.003921568859368563, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Identity',\n",
       "  'index': 25,\n",
       "  'shape': array([1, 4], dtype=int32),\n",
       "  'shape_signature': array([-1,  4], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.002142949728295207, -8),\n",
       "  'quantization_parameters': {'scales': array([0.00214295], dtype=float32),\n",
       "   'zero_points': array([-8], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'Identity_1',\n",
       "  'index': 27,\n",
       "  'shape': array([1, 2], dtype=int32),\n",
       "  'shape_signature': array([-1,  2], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.00390625, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00390625], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_predictions = np.zeros((len(v_data),), dtype= int)\n",
    "bbx_predictions = np.zeros((len(v_data), 4), dtype= int)\n",
    "input_scale, input_zero_point = input_details[0]['quantization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(v_data)):\n",
    "    val_batch = v_data[i]\n",
    "    val_batch = val_batch / input_scale + input_zero_point\n",
    "    val_batch = np.expand_dims(val_batch, axis = 0).astype(input_details[0]['dtype'])\n",
    "    tflite_interpreter.set_tensor(input_details[0]['index'], val_batch)\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    tflite_interpreter.invoke()\n",
    "    \n",
    "    # print(\"Prediction results shape:\", tflite_model_bbx_predictions.shape)\n",
    "    cat_output = tflite_interpreter.get_tensor(output_details[1]['index'])\n",
    "    bbx_output = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    cat_predictions[i] = cat_output.argmax()\n",
    "    bbx_predictions[i] = bbx_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbx_scale, bbx_zero_point = output_details[0]['quantization']\n",
    "bbx_predictions_f = (bbx_predictions.astype(float) - bbx_zero_point) * bbx_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_bbx = v_bbx.reshape(bbx_predictions_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.square(v_bbx - bbx_predictions_f).mean(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0058238648640499165"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [i.argmax() for i in v_cat.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_score = sum([1 for p, g in zip(cat_predictions, ground_truth) if p == g]) / len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7603 - BB_REGRESSION_loss: 0.0059 - FACE_CLASSIFIER_loss: 0.7573 - BB_REGRESSION_accuracy: 0.5000 - BB_REGRESSION_mse: 0.0059 - FACE_CLASSIFIER_accuracy: 0.8800 - FACE_CLASSIFIER_mse: 0.1018\n"
     ]
    }
   ],
   "source": [
    "n_score = model.evaluate(x= v_data, y = {'FACE_CLASSIFIER' : v_cat, 'BB_REGRESSION' : v_bbx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7602624297142029,\n",
       " 0.005854387301951647,\n",
       " 0.7573351860046387,\n",
       " 0.5,\n",
       " 0.005854387301951647,\n",
       " 0.8799999952316284,\n",
       " 0.10176583379507065]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That is a change of -4.768371586472142e-07 percent\n"
     ]
    }
   ],
   "source": [
    "print('That is a change of %s percent' % ((n_score[5] - q_score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
